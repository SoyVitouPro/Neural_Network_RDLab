{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "layer_output_1 = np.array([0.7, 1.1, 0.9])\n",
    "# Define E value\n",
    "E = math.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26930749917773783, 0.4017595785333555, 0.3289329222889067]\n"
     ]
    }
   ],
   "source": [
    "ex_values = []\n",
    "\n",
    "for ouput in layer_output_1:\n",
    "    ex_value = E ** ouput\n",
    "    ex_values.append(ex_value)\n",
    "\n",
    "sum_ex_values = np.sum(ex_values)\n",
    "\n",
    "probabilities = []\n",
    "for ex_value in ex_values:\n",
    "    probabilities.append(ex_value / sum_ex_values)\n",
    "\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this above code cannot handle for dataset as batchs, so let's make it possible below with created as class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created as Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "        # calculate exponential values\n",
    "        ex_values = np.exp(inputs)\n",
    "        sum_ex_values = [np.sum(ex_value) for ex_value in ex_values] # option2: np.sum(ex_values, axis=1)\n",
    "        self.output = [ex_value / sum_ex_value for ex_value, sum_ex_value in zip(ex_values, sum_ex_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00182884 0.9959374  0.00223376]\n",
      "[0.0089244  0.98121261 0.00986299]\n",
      "[0.02145645 0.95912894 0.0194146 ]\n"
     ]
    }
   ],
   "source": [
    "layer_output_batch = [[0.7, 7, 0.9], \n",
    "                      [0.3, 5, 0.4], \n",
    "                      [0.2, 4, 0.1]]\n",
    "\n",
    "softmax = Activation_Softmax()\n",
    "\n",
    "softmax.forward(layer_output_batch)\n",
    "for row in softmax.output:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- explain axis = 0, and axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.20e+00 5.02e+03 1.40e+00]\n",
      "[8.6000e+00 5.0097e+03 4.3000e+00]\n"
     ]
    }
   ],
   "source": [
    "layer_output_batch = np.array([[0.7, 7, 0.9], \n",
    "                      [0.3, 5, 0.4], \n",
    "                      [0.2, 4, 0.1]])\n",
    "\n",
    "output = np.sum(layer_output_batch, axis=0)\n",
    "output2 = np.sum(layer_output_batch, axis=1)\n",
    "\n",
    "print(output)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13164\\302018626.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  print (np.exp( 1000 ))\n"
     ]
    }
   ],
   "source": [
    "print (np.exp( 1000 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent the exponential function from overflowing or large number we can use all num minus with large num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "        # handle overflowing error\n",
    "        inputs = [np.subtract(input, np.max(input)) for input in inputs]\n",
    "        # calculate exponential values\n",
    "        ex_values = np.exp(inputs)\n",
    "        sum_ex_values = [np.sum(ex_value) for ex_value in ex_values] # option2: np.sum(ex_values, axis=1)\n",
    "        self.output = [ex_value / sum_ex_value for ex_value, sum_ex_value in zip(ex_values, sum_ex_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00182884 0.9959374  0.00223376]\n",
      "[0.00122773 0.99741542 0.00135685]\n",
      "[0.02145645 0.95912894 0.0194146 ]\n"
     ]
    }
   ],
   "source": [
    "layer_output_batch = [[0.7, 7, 0.9], \n",
    "                      [0.3, 7, 0.4], \n",
    "                      [0.2, 4, 0.1]]\n",
    "\n",
    "softmax = Activation_Softmax()\n",
    "\n",
    "softmax.forward(layer_output_batch)\n",
    "for row in softmax.output:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
